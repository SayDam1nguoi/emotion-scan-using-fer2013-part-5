import os
import sys
import tkinter as tk
from tkinter import filedialog, messagebox

sys.path.append(os.path.dirname(os.path.dirname(__file__)))

class MainWindow:
    def __init__(self, username, parent_root):
        self.username = username
        self.parent_root = parent_root
        self.root = tk.Toplevel()
        self.root.title(f"Emotion Scanner - {username}")
        
        # Get screen dimensions
        screen_width = self.root.winfo_screenwidth()
        screen_height = self.root.winfo_screenheight()
        
        # Set to 90% of screen size for better visibility
        window_width = int(screen_width * 0.9)
        window_height = int(screen_height * 0.9)
        
        self.root.geometry(f"{window_width}x{window_height}")
        self.root.resizable(True, True)  # Allow resizing
        
        # Optional: Start maximized
        # self.root.state('zoomed')  # Windows
        # self.root.attributes('-zoomed', True)  # Linux
        
        # Gradient background (adaptive to window size)
        canvas = tk.Canvas(self.root, highlightthickness=0)
        canvas.pack(fill="both", expand=True)
        
        # Create gradient (green to teal) - will be redrawn on resize
        def draw_gradient(event=None):
            canvas.delete("gradient")
            width = canvas.winfo_width()
            height = canvas.winfo_height()
            if height > 1:  # Ensure valid height
                for i in range(height):
                    ratio = i / height
                    r = int(39 + (26 - 39) * ratio)
                    g = int(174 + (188 - 174) * ratio)
                    b = int(96 + (156 - 96) * ratio)
                    color = f'#{r:02x}{g:02x}{b:02x}'
                    canvas.create_line(0, i, width, i, fill=color, tags="gradient")
        
        canvas.bind("<Configure>", draw_gradient)
        self.root.after(100, draw_gradient)  # Initial draw

        # Use larger frame that adapts to window size
        main_frame = tk.Frame(canvas, bg="#ffffff", relief=tk.FLAT)
        main_frame.place(relx=0.5, rely=0.5, anchor="center", relwidth=0.85, relheight=0.92)

        # Multi-layer shadow (adaptive)
        for offset in range(10, 0, -2):
            shadow = tk.Frame(canvas, bg=f"#{'%02x' % (200 - offset * 4)}{'%02x' % (200 - offset * 4)}{'%02x' % (200 - offset * 4)}")
            shadow.place(relx=0.5, rely=0.5 + offset/1000, anchor="center", 
                        relwidth=0.85 + offset/1000, relheight=0.92 + offset/1000)
            shadow.lower()

        header_frame = tk.Frame(main_frame, bg="#ffffff")
        header_frame.pack(fill=tk.X, pady=(20, 10))

        tk.Label(header_frame, text="üé≠", font=("Segoe UI Emoji", 60),
                 bg="#ffffff", fg="#27ae60").pack(pady=(10, 5))
        tk.Label(header_frame, text="Emotion Scanner", font=("Segoe UI", 26, "bold"),
                 bg="#ffffff", fg="#2c3e50").pack()
        tk.Label(header_frame, text=f"üëã  Xin ch√†o, {username}!", font=("Segoe UI", 13),
                 bg="#ffffff", fg="#7f8c8d").pack(pady=(5, 10))

        # Scrollable content frame
        content_canvas = tk.Canvas(main_frame, bg="#ffffff", highlightthickness=0)
        scrollbar = tk.Scrollbar(main_frame, orient="vertical", command=content_canvas.yview)
        content_frame = tk.Frame(content_canvas, bg="#ffffff")
        
        content_frame.bind(
            "<Configure>",
            lambda e: content_canvas.configure(scrollregion=content_canvas.bbox("all"))
        )
        
        content_canvas.create_window((0, 0), window=content_frame, anchor="nw")
        content_canvas.configure(yscrollcommand=scrollbar.set)
        
        content_canvas.pack(side="left", fill="both", expand=True, padx=60, pady=(5, 30))
        scrollbar.pack(side="right", fill="y")

        # Divider
        tk.Frame(content_frame, bg="#e1e8ed", height=2).pack(fill=tk.X, pady=(0, 20))

        file_card = tk.Frame(content_frame, bg="#f8f9fa",
                             highlightbackground="#27ae60", highlightthickness=2)
        file_card.pack(fill=tk.X, pady=(0, 15))

        tk.Label(file_card, text="üìÅ  File d·ªØ li·ªáu hu·∫•n luy·ªán",
                 font=("Segoe UI", 11, "bold"), bg="#f8f9fa", fg="#2c3e50").pack(
                     anchor="w", padx=18, pady=(15, 8))

        self.lbl_file = tk.Label(file_card, text="‚ö†Ô∏è  Ch∆∞a ch·ªçn file d·ªØ li·ªáu",
                                 font=("Segoe UI", 10), bg="#f8f9fa", fg="#e74c3c")
        self.lbl_file.pack(anchor="w", padx=18, pady=(0, 15))

        choose_btn = tk.Button(content_frame, text="üìÇ  Ch·ªçn file FER2013 (.csv)",
                               font=("Segoe UI", 11, "bold"), bg="#3498db", fg="white",
                               relief=tk.FLAT, cursor="hand2", borderwidth=0,
                               activebackground="#2980b9", activeforeground="white",
                               command=self.choose_file)
        choose_btn.pack(fill=tk.X, pady=(0, 20), ipady=14)

        choose_btn.bind("<Enter>", lambda e: choose_btn.configure(bg="#2980b9"))
        choose_btn.bind("<Leave>", lambda e: choose_btn.configure(bg="#3498db"))

        video_card = tk.Frame(content_frame, bg="#f8f9fa",
                              highlightbackground="#9b59b6", highlightthickness=2)
        video_card.pack(fill=tk.X, pady=(0, 15))

        tk.Label(video_card, text="üéûÔ∏è  Video ƒë·ªÉ ph√¢n t√≠ch",
                 font=("Segoe UI", 11, "bold"), bg="#f8f9fa", fg="#2c3e50").pack(
                     anchor="w", padx=18, pady=(15, 8))

        self.lbl_video = tk.Label(video_card, text="‚ÑπÔ∏è  Ch∆∞a ch·ªçn video (t√πy ch·ªçn)",
                                  font=("Segoe UI", 10), bg="#f8f9fa", fg="#95a5a6")
        self.lbl_video.pack(anchor="w", padx=18, pady=(0, 15))

        video_btn = tk.Button(content_frame, text="üé¨  Ch·ªçn video (.mp4 / .avi)",
                              font=("Segoe UI", 11, "bold"), bg="#9b59b6", fg="white",
                              relief=tk.FLAT, cursor="hand2", borderwidth=0,
                              activebackground="#8e44ad", activeforeground="white",
                              command=self.choose_video)
        video_btn.pack(fill=tk.X, pady=(0, 25), ipady=14)

        video_btn.bind("<Enter>", lambda e: video_btn.configure(bg="#8e44ad"))
        video_btn.bind("<Leave>", lambda e: video_btn.configure(bg="#9b59b6"))
        
        # Section divider
        tk.Label(content_frame, text="‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  B·∫Øt ƒë·∫ßu qu√©t  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
                 font=("Segoe UI", 9), bg="#ffffff", fg="#bdc3c7").pack(pady=(5, 20))

        # 1. Camera Card
        camera_card = tk.Frame(content_frame, bg="#f8f9fa",
                              highlightbackground="#27ae60", highlightthickness=3)
        camera_card.pack(fill=tk.X, pady=(0, 15))
        
        camera_inner = tk.Frame(camera_card, bg="#f8f9fa")
        camera_inner.pack(fill=tk.X, padx=3, pady=3)
        
        detect_cam_btn = tk.Button(camera_inner, text="üì∏  Qu√©t c·∫£m x√∫c qua Camera",
                                   font=("Segoe UI", 12, "bold"), bg="#27ae60", fg="white",
                                   relief=tk.FLAT, cursor="hand2", borderwidth=0,
                                   activebackground="#229954", activeforeground="white",
                                   command=self.detect_emotion_camera)
        detect_cam_btn.pack(side=tk.LEFT, fill=tk.X, expand=True, ipady=14)
        detect_cam_btn.bind("<Enter>", lambda e: detect_cam_btn.configure(bg="#229954"))
        detect_cam_btn.bind("<Leave>", lambda e: detect_cam_btn.configure(bg="#27ae60"))
        
        detect_cam_roi_btn = tk.Button(camera_inner, text="üéØ",
                                       font=("Segoe UI", 14, "bold"), bg="#229954", fg="white",
                                       relief=tk.FLAT, cursor="hand2", borderwidth=0,
                                       activebackground="#1e8449", activeforeground="white",
                                       command=self.detect_emotion_camera_roi, width=3)
        detect_cam_roi_btn.pack(side=tk.LEFT, padx=(5, 0), ipady=14)
        detect_cam_roi_btn.bind("<Enter>", lambda e: detect_cam_roi_btn.configure(bg="#1e8449"))
        detect_cam_roi_btn.bind("<Leave>", lambda e: detect_cam_roi_btn.configure(bg="#229954"))
        
        select_cam_btn = tk.Button(camera_inner, text="üìπ",
                                   font=("Segoe UI", 14, "bold"), bg="#16a085", fg="white",
                                   relief=tk.FLAT, cursor="hand2", borderwidth=0,
                                   activebackground="#138d75", activeforeground="white",
                                   command=self.select_camera, width=3)
        select_cam_btn.pack(side=tk.LEFT, padx=(5, 0), ipady=14)
        select_cam_btn.bind("<Enter>", lambda e: select_cam_btn.configure(bg="#138d75"))
        select_cam_btn.bind("<Leave>", lambda e: select_cam_btn.configure(bg="#16a085"))
        
        tk.Label(content_frame, text="üí° üéØ Ch·ªçn v√πng | üìπ Ch·ªçn camera",
                font=("Segoe UI", 8), bg="#ffffff", fg="#7f8c8d").pack(pady=(0, 15))

        # 2. Video Card
        video_detect_card = tk.Frame(content_frame, bg="#f8f9fa",
                                     highlightbackground="#e67e22", highlightthickness=3)
        video_detect_card.pack(fill=tk.X, pady=(0, 15))
        
        detect_video_btn = tk.Button(video_detect_card, text="üé•  Qu√©t c·∫£m x√∫c t·ª´ Video",
                                     font=("Segoe UI", 12, "bold"), bg="#e67e22", fg="white",
                                     relief=tk.FLAT, cursor="hand2", borderwidth=0,
                                     activebackground="#d35400", activeforeground="white",
                                     command=self.detect_emotion_video)
        detect_video_btn.pack(fill=tk.X, padx=3, pady=3, ipady=14)
        detect_video_btn.bind("<Enter>", lambda e: detect_video_btn.configure(bg="#d35400"))
        detect_video_btn.bind("<Leave>", lambda e: detect_video_btn.configure(bg="#e67e22"))
        
        # 3. Screen Capture Card
        screen_card = tk.Frame(content_frame, bg="#f8f9fa",
                              highlightbackground="#8e44ad", highlightthickness=3)
        screen_card.pack(fill=tk.X, pady=(0, 15))
        
        detect_screen_btn = tk.Button(screen_card, text="üíª  Qu√©t t·ª´ M√†n h√¨nh (App b·∫•t k·ª≥)",
                                      font=("Segoe UI", 12, "bold"), bg="#8e44ad", fg="white",
                                      relief=tk.FLAT, cursor="hand2", borderwidth=0,
                                      activebackground="#6c3483", activeforeground="white",
                                      command=self.detect_emotion_screen)
        detect_screen_btn.pack(fill=tk.X, padx=3, pady=3, ipady=14)
        detect_screen_btn.bind("<Enter>", lambda e: detect_screen_btn.configure(bg="#6c3483"))
        detect_screen_btn.bind("<Leave>", lambda e: detect_screen_btn.configure(bg="#8e44ad"))
        
        tk.Label(content_frame, text="üí° YouTube, Netflix, Zoom, phim, app b·∫•t k·ª≥",
                font=("Segoe UI", 8), bg="#ffffff", fg="#7f8c8d").pack(pady=(0, 15))
        
        # 4. Dual Detection Card
        dual_card = tk.Frame(content_frame, bg="#f8f9fa",
                            highlightbackground="#e74c3c", highlightthickness=3)
        dual_card.pack(fill=tk.X, pady=(0, 30))
        
        detect_dual_btn = tk.Button(dual_card, text="üë•  Qu√©t C·∫¢ 2 NG∆Ø·ªúI (Camera + M√†n h√¨nh)",
                                    font=("Segoe UI", 12, "bold"), bg="#e74c3c", fg="white",
                                    relief=tk.FLAT, cursor="hand2", borderwidth=0,
                                    activebackground="#c0392b", activeforeground="white",
                                    command=self.detect_emotion_dual)
        detect_dual_btn.pack(fill=tk.X, padx=3, pady=3, ipady=14)
        detect_dual_btn.bind("<Enter>", lambda e: detect_dual_btn.configure(bg="#c0392b"))
        detect_dual_btn.bind("<Leave>", lambda e: detect_dual_btn.configure(bg="#e74c3c"))
        
        # Bottom divider
        tk.Frame(content_frame, bg="#e1e8ed", height=2).pack(fill=tk.X, pady=(5, 15))

        logout_btn = tk.Button(content_frame, text="üö™  ƒêƒÉng xu·∫•t",
                               font=("Segoe UI", 10, "bold"), bg="#ffffff", fg="#e74c3c",
                               relief=tk.FLAT, cursor="hand2", borderwidth=0,
                               activebackground="#f8f9fa", activeforeground="#c0392b",
                               command=self.logout)
        logout_btn.pack(fill=tk.X, ipady=10)
        
        def on_logout_enter(e):
            logout_btn.configure(bg="#f8f9fa")
        
        def on_logout_leave(e):
            logout_btn.configure(bg="#ffffff")
        
        logout_btn.bind("<Enter>", on_logout_enter)
        logout_btn.bind("<Leave>", on_logout_leave)

        self.csv_path = ""
        self.video_path = ""
        self.camera_id = 0  # Default camera

        self.root.protocol("WM_DELETE_WINDOW", self.logout)

        # Center window on screen
        self.root.update_idletasks()
        x = (screen_width - window_width) // 2
        y = (screen_height - window_height) // 2
        self.root.geometry(f"{window_width}x{window_height}+{x}+{y}")

    def choose_file(self):
        path = filedialog.askopenfilename(title="Ch·ªçn file FER2013 (fer2013.csv)",
                                          filetypes=[("CSV files", "*.csv")])
        if path:
            self.csv_path = path
            filename = os.path.basename(path)
            self.lbl_file.config(text=f"‚úÖ  {filename}", fg="#27ae60")
        else:
            self.lbl_file.config(text="‚ö†Ô∏è  Ch∆∞a ch·ªçn file d·ªØ li·ªáu", fg="#e74c3c")

    def choose_video(self):
        path = filedialog.askopenfilename(title="Ch·ªçn video",
                                          filetypes=[("Video files", "*.mp4 *.avi *.mov")])
        if path:
            self.video_path = path
            self.lbl_video.config(text=f"‚úÖ  {os.path.basename(path)}", fg="#9b59b6")
        else:
            self.lbl_video.config(text="‚ÑπÔ∏è  Ch∆∞a ch·ªçn video (t√πy ch·ªçn)", fg="#95a5a6")

    def select_camera(self):
        """Ch·ªçn camera t·ª´ danh s√°ch"""
        try:
            from core.camera_selector import select_camera_gui
            
            selected = select_camera_gui()
            if selected is not None:
                self.camera_id = selected
                messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ ch·ªçn Camera {selected}")
            
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ ch·ªçn camera:\n{str(e)}")
    
    def detect_emotion_camera(self):
        """Qu√©t to√†n b·ªô camera (kh√¥ng ROI)"""
        if not self.csv_path:
            messagebox.showerror("L·ªói", "Vui l√≤ng ch·ªçn file FER2013 (.csv) tr∆∞·ªõc!")
            return
        
        # Import and start detection (loading window will show inside start_detection)
        from core.detector import start_detection
        
        try:
            start_detection(self.csv_path, camera_id=self.camera_id)
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông camera:\n{str(e)}")
    
    def detect_emotion_camera_roi(self):
        """Qu√©t v√πng c·ª• th·ªÉ trong camera (v·ªõi ROI)"""
        if not self.csv_path:
            messagebox.showerror("L·ªói", "Vui l√≤ng ch·ªçn file FER2013 (.csv) tr∆∞·ªõc!")
            return
        
        # Show instructions
        msg = ("QU√âT V√ôNG C·ª§ TH·ªÇ TRONG CAMERA:\n\n"
               "T√≠nh nƒÉng n√†y cho ph√©p b·∫°n ch·ªçn 1 v√πng c·ª• th·ªÉ\n"
               "trong khung h√¨nh camera ƒë·ªÉ qu√©t.\n\n"
               "H·ªÆU √çCH KHI:\n"
               "- C√≥ nhi·ªÅu ng∆∞·ªùi trong khung h√¨nh\n"
               "- Ch·ªâ mu·ªën qu√©t 1 ng∆∞·ªùi c·ª• th·ªÉ\n"
               "- TƒÉng hi·ªáu nƒÉng x·ª≠ l√Ω\n\n"
               "H∆Ø·ªöNG D·∫™N:\n"
               "1. Camera s·∫Ω m·ªü\n"
               "2. K√©o chu·ªôt ƒë·ªÉ ch·ªçn v√πng\n"
               "3. Nh·∫•n ENTER ƒë·ªÉ x√°c nh·∫≠n\n"
               "4. Nh·∫•n SPACE ƒë·ªÉ ch·ª•p l·∫°i frame m·ªõi\n\n"
               "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c?")
        
        result = messagebox.askokcancel("Qu√©t v√πng Camera", msg)
        if not result:
            return
        
        try:
            # Import camera ROI selector
            from core.camera_roi import select_camera_roi
            from core.detector import start_detection_camera_roi
            
            # Let user select ROI
            messagebox.showinfo("Ch·ªçn v√πng", 
                              "K√©o chu·ªôt ƒë·ªÉ ch·ªçn v√πng c·∫ßn qu√©t\n"
                              "ENTER: X√°c nh·∫≠n | ESC: H·ªßy | SPACE: Ch·ª•p l·∫°i")
            
            roi = select_camera_roi(camera_id=self.camera_id)
            
            print(f"DEBUG UI: ROI returned = {roi}, type = {type(roi)}")
            
            if roi is None:
                messagebox.showinfo("ƒê√£ h·ªßy", "ƒê√£ h·ªßy ch·ªçn v√πng")
                return
            
            # Validate ROI format
            if not isinstance(roi, tuple) or len(roi) != 4:
                messagebox.showerror("L·ªói", f"ROI kh√¥ng h·ª£p l·ªá: type={type(roi)}, value={roi}")
                return
            
            print(f"DEBUG UI: ROI validated, passing to detector")
            
            # Start detection with ROI
            start_detection_camera_roi(self.csv_path, roi, self.camera_id)
            
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông camera ROI:\n{str(e)}")

    def detect_emotion_video(self):
        if not self.csv_path:
            messagebox.showerror("L·ªói", "Vui l√≤ng ch·ªçn file FER2013 (.csv)!")
            return
        if not self.video_path:
            messagebox.showerror("L·ªói", "Vui l√≤ng ch·ªçn video!")
            return
        
        # Import and start detection (loading window will show inside start_detection)
        from core.detector import start_detection
        
        try:
            start_detection(self.csv_path, video_path=self.video_path)
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ t·∫£i video:\n{str(e)}")
    
    def detect_emotion_screen(self):
        """Qu√©t c·∫£m x√∫c t·ª´ screen capture (video call)"""
        if not self.csv_path:
            messagebox.showerror("L·ªói", "Vui l√≤ng ch·ªçn file FER2013 (.csv) tr∆∞·ªõc!")
            return
        
        # Show instructions
        msg = ("QU√âT T·ª™ M√ÄN H√åNH:\n\n"
               "Qu√©t khu√¥n m·∫∑t t·ª´ B·∫§T K·ª≤ ·ª©ng d·ª•ng n√†o:\n"
               "‚Ä¢ Video call (Zoom, Teams, Meet)\n"
               "‚Ä¢ Video YouTube, Netflix, phim\n"
               "‚Ä¢ ·ª®ng d·ª•ng kh√°c c√≥ khu√¥n m·∫∑t\n\n"
               "H∆Ø·ªöNG D·∫™N:\n"
               "1. M·ªü ·ª©ng d·ª•ng c·∫ßn qu√©t\n"
               "2. Nh·∫•n OK ƒë·ªÉ ch·ªçn v√πng m√†n h√¨nh\n"
               "3. K√©o chu·ªôt ch·ªçn v√πng c√≥ khu√¥n m·∫∑t\n"
               "4. Nh·∫•n ENTER x√°c nh·∫≠n\n\n"
               "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c?")
        
        result = messagebox.askokcancel("Qu√©t t·ª´ M√†n h√¨nh", msg)
        if not result:
            return
        
        try:
            # Import screen capture
            from core.screen_capture import select_capture_region_interactive
            from core.detector import start_detection_screen
            
            # Let user select region
            messagebox.showinfo("Ch·ªçn v√πng m√†n h√¨nh", 
                              "K√©o chu·ªôt ƒë·ªÉ ch·ªçn v√πng c√≥ khu√¥n m·∫∑t\n"
                              "C√≥ th·ªÉ l√†: Video call, YouTube, phim, app b·∫•t k·ª≥\n"
                              "ENTER: X√°c nh·∫≠n | ESC: H·ªßy")
            
            region = select_capture_region_interactive()
            
            if region is None:
                messagebox.showinfo("ƒê√£ h·ªßy", "ƒê√£ h·ªßy ch·ªçn v√πng")
                return
            
            # Start detection with screen capture
            start_detection_screen(self.csv_path, region)
            
        except ImportError:
            messagebox.showerror("L·ªói", 
                               "Thi·∫øu th∆∞ vi·ªán 'mss'!\n\n"
                               "C√†i ƒë·∫∑t b·∫±ng l·ªánh:\n"
                               "pip install mss")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ capture m√†n h√¨nh:\n{str(e)}")
    
    def detect_emotion_dual(self):
        """Qu√©t c·∫£m x√∫c C·∫¢ 2 NG∆Ø·ªúI - Camera + Screen"""
        if not self.csv_path:
            messagebox.showerror("L·ªói", "Vui l√≤ng ch·ªçn file FER2013 (.csv) tr∆∞·ªõc!")
            return
        
        # Show instructions
        msg = ("QU√âT C·∫¢ 2 NG∆Ø·ªúI TRONG VIDEO CALL:\n\n"
               "üìπ Camera: Qu√©t CH√çNH B·∫†N\n"
               "üíª Screen: Qu√©t NG∆Ø·ªúI ƒê·ªêI DI·ªÜN\n\n"
               "H∆Ø·ªöNG D·∫™N:\n"
               "1. M·ªü ·ª©ng d·ª•ng video call\n"
               "2. B·∫Øt ƒë·∫ßu cu·ªôc g·ªçi\n"
               "3. Ch·ªçn v√πng m√†n h√¨nh ch·ª©a khu√¥n m·∫∑t ng∆∞·ªùi ƒë·ªëi di·ªán\n"
               "4. H·ªá th·ªëng s·∫Ω qu√©t C·∫¢ 2 NG∆Ø·ªúI ƒë·ªìng th·ªùi\n\n"
               "K·∫æT QU·∫¢:\n"
               "- So s√°nh c·∫£m x√∫c 2 b√™n\n"
               "- Ai t√≠ch c·ª±c h∆°n?\n"
               "- Ai t·∫≠p trung h∆°n?\n\n"
               "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c?")
        
        result = messagebox.askokcancel("Qu√©t C·∫£ 2 Ng∆∞·ªùi", msg)
        if not result:
            return
        
        try:
            # Import modules
            from core.screen_capture import select_capture_region_interactive
            from core.detector import start_detection_dual
            
            # Let user select region for person 2 (screen)
            messagebox.showinfo("Ch·ªçn v√πng ng∆∞·ªùi ƒë·ªëi di·ªán", 
                              "K√©o chu·ªôt ƒë·ªÉ ch·ªçn v√πng khu√¥n m·∫∑t NG∆Ø·ªúI ƒê·ªêI DI·ªÜN\n"
                              "Nh·∫•n ENTER ƒë·ªÉ x√°c nh·∫≠n, ESC ƒë·ªÉ h·ªßy")
            
            region = select_capture_region_interactive()
            
            if region is None:
                messagebox.showinfo("ƒê√£ h·ªßy", "ƒê√£ h·ªßy ch·ªçn v√πng")
                return
            
            # Start dual detection
            start_detection_dual(self.csv_path, region)
            
        except ImportError:
            messagebox.showerror("L·ªói", 
                               "Thi·∫øu th∆∞ vi·ªán 'mss'!\n\n"
                               "C√†i ƒë·∫∑t b·∫±ng l·ªánh:\n"
                               "pip install mss")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu dual detection:\n{str(e)}")

    def logout(self):
        self.root.destroy()
        self.parent_root.deiconify()


def open_main_window(username, parent_root):
    MainWindow(username, parent_root)
